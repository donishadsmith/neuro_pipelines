#!/bin/bash
#SBATCH --job-name=threshold_palm
#SBATCH --partition=cpu
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=16G
# Outputs -----------------------------------------------------------------------
#SBATCH --output=/projects/bigos_lab/mph-study/code/logs/threshold_palm_%A_%a.out
#SBATCH --error=/projects/bigos_lab/mph-study/code/logs/threshold_palm_%A_%a.err
# -------------------------------------------------------------------------------
DATASET="mph"
COHORT="kids"
ANALYSIS_TYPE="glm" # glm or gPPI
CLUSTER_CORRECTION_P=0.05

BIDS_DIR="/projects/bigos_lab/mph-study/kids/dset"
ANALYSIS_DIR="$BIDS_DIR/derivatives/$ANALYSIS_TYPE"
PYTHON="/projects/bigos_lab/envs/py313/bin/python"

DEFAULT_TASKS=("nback" "mtle" "mtlr" "princess" "flanker")

# sbatch --array=0 second_level.sb # values map to SLURM_ARRAY_TASK_ID for indexing TASK array
TASKS=( $@ )
# slurm job value; essentially extracting sub-id
if [ ${#TASKS[@]} -eq 0 ]; then
    TASK="${DEFAULT_TASKS[$SLURM_ARRAY_TASK_ID]}"
else
	TASK="${TASKS[$SLURM_ARRAY_TASK_ID]}"
fi

DST_DIR="$ANALYSIS_DIR/$TASK"
mkdir -p $DST_DIR

CMD="$PYTHON threshold_palm.py \
    --analysis_dir $ANALYSIS_DIR \
	--dst_dir $DST_DIR \
    --task $TASK \
    --analysis_type $ANALYSIS_TYPE \
    --dataset $DATASET \
    --cohort $COHORT \
    --cluster_correction_p $CLUSTER_CORRECTION_P"

echo Task ID: $SLURM_ARRAY_TASK_ID
echo Commandline: $CMD
eval $CMD

echo Exit Code: $?
date
exit $?
