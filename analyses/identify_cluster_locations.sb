#!/bin/bash
#SBATCH --job-name=identify_cluster_locations
#SBATCH --partition=cpu
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=16G
# Outputs ------------------------------------------------------------------------------------
#SBATCH --output=/projects/bigos_lab/mph-study/code/logs/identify_cluster_locations_%A_%a.out
#SBATCH --error=/projects/bigos_lab/mph-study/code/logs/identify_cluster_locations_%A_%a.err
# --------------------------------------------------------------------------------------------
USERNAME=${HOME#/home/}
ANALYSIS_TYPE=${ANALYSIS_TYPE:-glm} # glm or gPPI
METHOD=${METHOD:-nonparametric}
WHEREAMI_ATLAS=${WHEREAMI_ATLAS:-"Haskins_Pediatric_Nonlinear_1.0"}

BIDS_DIR="/projects/bigos_lab/mph-study/kids/dset"
PYTHON="/projects/bigos_lab/envs/py313/bin/python"
AFNI_IMG_PATH="/projects/bigos_lab/apptainer-images/afni_23.0.07_20230302.simg"

DEFAULT_TASKS=("nback" "mtle" "mtlr" "princess" "flanker")

# sbatch --array=0 identify_cluster_locations.sb # values map to SLURM_ARRAY_TASK_ID for indexing TASK array
TASKS=( $@ )
# slurm job value; essentially extracting sub-{id}
if [ ${#TASKS[@]} -eq 0 ]; then
    TASK=${DEFAULT_TASKS[${SLURM_ARRAY_TASK_ID}]}
else
	TASK=${TASKS[${SLURM_ARRAY_TASK_ID}]}
fi

ANALYSIS_DIR="$BIDS_DIR/derivatives/$ANALYSIS_TYPE/$TASK"
SCRATCH_DIR="/scratch/$USERNAME/mph/kids/mni_coordinate_files"
mkdir -p $SCRATCH_DIR

CMD="$PYTHON identify_cluster_locations.py \
    --analysis_dir $ANALYSIS_DIR \
    --scratch_dir $SCRATCH_DIR \
	--afni_img_path $AFNI_IMG_PATH \
	--task $TASK \
    --method $METHOD \
    --atlas $WHEREAMI_ATLAS \
    --analysis_type $ANALYSIS_TYPE"

# hostname
# id
# getent passwd "$(id -u)" || echo "getent failed"

echo Task ID: $SLURM_ARRAY_TASK_ID
echo Commandline: $CMD
eval $CMD

echo Exit Code: $?
date
exit $?
